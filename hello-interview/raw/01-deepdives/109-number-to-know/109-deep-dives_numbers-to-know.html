<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Numbers to Know for System Design Interviews</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <div><div class="flex flex-col gap-2 md:gap-4"><div class="flex flex-col"><h6 class="MuiTypography-root MuiTypography-h6 mui-zfm63x">Deep Dives</h6><h1 class="MuiTypography-root MuiTypography-h2 mui-161snwm">Numbers to Know</h1><p class="MuiTypography-root MuiTypography-body2 mui-45a2r">Understand what modern hardware can actually handle in 2025.</p></div></div><hr class="MuiDivider-root MuiDivider-fullWidth mui-1rvhejo"></div>
<h2 class="MuiTypography-root MuiTypography-h3 mui-1rzqq5q" id="intro">Intro</h2>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">Our industry moves fast. The hardware we build systems on evolves constantly, which means even recent textbooks can become outdated quickly. A book published just a few years ago might be teaching patterns that still make sense, but quoting numbers that are off by orders of magnitude.</div>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">One of the biggest giveaways that a candidate has book knowledge but no hands-on experience during a system design interview is when they rely on outdated hardware constraints. They do scale calculations using numbers from 2015 (or even 2020!) that dramatically underestimate what modern systems can handle. You'll hear concerns about database sizes, memory limits, and storage costs that made sense then, but would lead to significantly over-engineered systems today.</div>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">This isn't the candidate's fault – they're doing the right thing by studying. But understanding modern hardware capabilities is crucial for making good system design decisions. When to shard a database, whether to cache aggressively, how to handle large objects – these choices all depend on having an accurate sense of what today's hardware can handle.</div>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">Let's look at the numbers that actually matter in 2025.</div>
<h2 class="MuiTypography-root MuiTypography-h3 mui-1rzqq5q" id="modern-hardware-limits">Modern Hardware Limits</h2>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">Modern servers pack serious computing power. An AWS <a class="MuiTypography-root MuiTypography-inherit MuiLink-root MuiLink-underlineHover mui-pvpazu" href="https://aws.amazon.com/ec2/instance-types/m6i/" target="_blank" rel="noopener noreferrer" style="color: rgb(99, 115, 129); cursor: pointer; font-weight: 600; text-decoration: underline;">M6i.32xlarge</a> comes with 512 GiB of memory and 128 vCPUs for general workloads. Memory-optimized instances go further: the <a class="MuiTypography-root MuiTypography-inherit MuiLink-root MuiLink-underlineHover mui-pvpazu" href="https://aws.amazon.com/ec2/instance-types/x1e/" target="_blank" rel="noopener noreferrer" style="color: rgb(99, 115, 129); cursor: pointer; font-weight: 600; text-decoration: underline;">X1e.32xlarge</a> provides 4 TB of RAM, while the <a class="MuiTypography-root MuiTypography-inherit MuiLink-root MuiLink-underlineHover mui-pvpazu" href="https://aws.amazon.com/blogs/aws/ec2-high-memory-update-new-18-tb-and-24-tb-instances/" target="_blank" rel="noopener noreferrer" style="color: rgb(99, 115, 129); cursor: pointer; font-weight: 600; text-decoration: underline;">U-24tb1.metal</a> reaches 24 TB of RAM. This shift matters because many applications that once required distributed systems can now run on a single machine.</div>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">Storage capacity has seen similar growth. Modern instances like AWS's <a class="MuiTypography-root MuiTypography-inherit MuiLink-root MuiLink-underlineHover mui-pvpazu" href="https://aws.amazon.com/ec2/instance-types/i3en/" target="_blank" rel="noopener noreferrer" style="color: rgb(99, 115, 129); cursor: pointer; font-weight: 600; text-decoration: underline;">i3en.24xlarge</a> provide 60 TB of local SSD storage. If you need more, the <a class="MuiTypography-root MuiTypography-inherit MuiLink-root MuiLink-underlineHover mui-pvpazu" href="https://aws.amazon.com/ec2/instance-types/d3/" target="_blank" rel="noopener noreferrer" style="color: rgb(99, 115, 129); cursor: pointer; font-weight: 600; text-decoration: underline;">D3en.12xlarge</a> offers 336 TB of HDD storage for data-heavy workloads. Object storage like <a class="MuiTypography-root MuiTypography-inherit MuiLink-root MuiLink-underlineHover mui-pvpazu" href="https://aws.amazon.com/s3/" target="_blank" rel="noopener noreferrer" style="color: rgb(99, 115, 129); cursor: pointer; font-weight: 600; text-decoration: underline;">S3</a> is effectively unlimited, handling petabyte-scale deployments as a standard practice. The days of storage being a primary constraint are largely behind us.</div>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">Network capabilities haven't stagnated either. Within a datacenter, 10 Gbps is standard, with high-performance instances supporting up to 20 Gbps. Cross-region bandwidth typically ranges from 100 Mbps to 1 Gbps. Latency remains predictable: 1-2ms within a region, and 50-150ms cross-region. This consistent performance allows for reliable distributed system design.</div>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">These aren't just incremental improvements – they represent a step change in what's possible. When textbooks talk about splitting databases at 100GB or avoiding large objects in memory, they're working from outdated constraints. The hardware running our systems today would have been unimaginable a decade ago, and these capabilities fundamentally change how we approach system design.</div>
<h2 class="MuiTypography-root MuiTypography-h3 mui-1rzqq5q" id="applying-these-numbers-in-system-design-interviews">Applying These Numbers in System Design Interviews</h2>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">Let's look at how these numbers impact specific components and the decisions we make when designing systems in an interview.</div>
<div><h3 class="MuiTypography-root MuiTypography-h4 mui-hkpafq" id="caching">Caching</h3><div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">In-memory caches have grown exponentially in both size and capability. Gone are the days of 32-64GB Redis instances that required careful memory management and partial dataset caching. Today's caches routinely handle terabyte-scale datasets with single-digit millisecond latency, and a single instance can process hundreds of thousands of operations per second. This shift in scale changes the entire approach to caching strategy.</div><div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">Numbers to know:</div><ul class="MuiList-root MuiList-padding mui-sedpvs">
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0">Memory: Up to 1TB on memory-optimized instances, with some configurations exceeding this for specialized use cases</div></li>
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0">Latency
<ul class="MuiList-root MuiList-padding mui-sedpvs">
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0">Reads: &lt; 1ms within the same region</div></li>
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0">Writes: 1-2ms average cross-region for optimized systems</div></li>
</ul>
</div></li>
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0">Throughput
<ul class="MuiList-root MuiList-padding mui-sedpvs">
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0">Reads: Over 100k requests/second per instance for in-memory caches like ElastiCache Redis on modern Graviton-based nodes</div></li>
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0">Writes: Sustained throughput of hundreds of thousands of requests per second</div></li>
</ul>
</div></li>
</ul><div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">When to consider sharding:</div><ul class="MuiList-root MuiList-padding mui-sedpvs">
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0">Dataset Size: Approaching 1TB in size</div></li>
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0">Throughout: Sustained throughput of 100k+ ops/second</div></li>
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0">Read Latency: Requirements below 0.5ms consistently (if being exceeded, consider sharding)</div></li>
</ul><div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">These capabilities fundamentally change caching strategy. The ability to cache entire databases in memory, even at hundreds of gigabytes, means you can often avoid complex partial caching schemes altogether. This "cache everything" approach, while seemingly brute force, typically costs less than engineering time spent on selective caching logic. When you do need to scale, the bottleneck is usually operations per second or network bandwidth, not memory size – a counterintuitive shift from just a few years ago.</div><h3 class="MuiTypography-root MuiTypography-h4 mui-hkpafq" id="databases">Databases</h3><div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">The raw power of modern databases surprises even experienced engineers. Single PostgreSQL or MySQL instances now routinely handle dozens of terabytes of data while maintaining millisecond-level response times. This isn't just about storage either. Modern databases efficiently handle tens of thousands of transactions per second on a single primary, with the bottleneck often being operational concerns rather than performance limits.</div><div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">Numbers to know:</div><ul class="MuiList-root MuiList-padding mui-sedpvs">
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0">Storage: Single instances handle up to 64 TiB (terabytes) for most database engines, with Aurora supporting up to 128 TiB in some configurations</div></li>
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0">Latency
<ul class="MuiList-root MuiList-padding mui-sedpvs">
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0">Reads: 1-5ms for cached data, 5-30ms for disk (optimized configurations for RDS and Aurora)</div></li>
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0">Writes: 5-15ms for commit latency (for single-node, high-performance setups)</div></li>
</ul>
</div></li>
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0">Throughput
<ul class="MuiList-root MuiList-padding mui-sedpvs">
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0">Reads: Up to 50k TPS in single-node configurations on Aurora and RDS</div></li>
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0">Writes: 10-20k TPS in single-node configurations on Aurora and RDS</div></li>
</ul>
</div></li>
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0">Connections: 5-20k concurrent connections, depending on database and instance type</div></li>
</ul><div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">When to consider sharding:</div><ul class="MuiList-root MuiList-padding mui-sedpvs">
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0">Dataset Size: Approaching or exceeding 50 TiB may require sharding or distributed solutions</div></li>
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0">Write Throughput: Consistently exceeding 10k TPS indicates scaling considerations</div></li>
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0">Read Latency: Requirements below 5ms for uncached data may necessitate optimization</div></li>
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0">Geographic Distribution: Cross-region replication or distribution needs</div></li>
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0">Backup/Recovery: Backup windows that stretch into hours or become operationally impractical</div></li>
</ul><div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">While the largest systems in the world (social networks, e-commerce giants, etc.) absolutely need sharding to handle their scale, many candidates jump to distributed solutions too early. For systems handling millions or even tens of millions of users, a well-tuned single database can often handle the load. When you do need to scale, carefully consider what's driving the decision: is it pure data volume, operational concerns like backup windows, or the need for geographic distribution? Understanding these tradeoffs leads to better scaling decisions.</div><div class="my-6"><div class="MuiBox-root mui-o9fqh4"><div class="MuiBox-root mui-3t6lyr"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="w-6 h-6 heroicon-sw-2"><path stroke-linecap="round" stroke-linejoin="round" d="M12 9v3.75m-9.303 3.376c-.866 1.5.217 3.374 1.948 3.374h14.71c1.73 0 2.813-1.874 1.948-3.374L13.949 3.378c-.866-1.5-3.032-1.5-3.898 0L2.697 16.126ZM12 15.75h.007v.008H12v-.008Z"></path></svg></div><div class="MuiBox-root mui-79elbk"><div style="overflow: hidden; max-height: 300px;"><div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">More often then not I see candidates reaching for scaling too quickly. They have 500GB or a couple of terabytes of data and they're start explaining how they'd shard the database. Slow down, do the math, and make sure sharding is actually needed before you start explaining how you'd do it.</div></div></div></div></div><h3 class="MuiTypography-root MuiTypography-h4 mui-hkpafq" id="application-servers">Application Servers</h3><div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">Modern application servers have evolved beyond the resource constraints that shaped many traditional design patterns. Today's servers routinely handle thousands of concurrent connections with modest resource usage, while cloud platforms enable near-instant scaling in response to load. CPU processing power, rather than memory or connection limits, typically determines your server's capabilities.</div><div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">Numbers to know:</div><ul class="MuiList-root MuiList-padding mui-sedpvs">
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0">Connections: 100k+ concurrent connections per instance for optimized configurations</div></li>
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0">CPU: 8-64 cores</div></li>
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0">Memory: 64-512GB standard, up to 2TB available for high-memory instances</div></li>
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0">Network: Up to 25 Gbps bandwidth in modern server configurations</div></li>
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0">Startup Time: 30-60 seconds for containerized apps</div></li>
</ul><div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">When to consider sharding:</div><ul class="MuiList-root MuiList-padding mui-sedpvs">
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0">CPU Utilization: Consistently above 70-80%</div></li>
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0">Response Latency: Exceeding SLA or critical thresholds</div></li>
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0">Memory Usage: Trending above 70-80%</div></li>
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0">Network Bandwidth: Approaching 20 Gbps</div></li>
</ul><div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">The implications for system design are significant. While the trend toward stateless services is valuable for scaling, don't forget that each server has substantial memory available. Local caching, in-memory computations, and session handling can all leverage this memory to improve performance dramatically. CPU is almost always your first bottleneck, not memory, so don't shy away from memory-intensive optimizations when they make sense. When you do need to scale, cloud platforms can spin up new instances in seconds, making aggressive auto-scaling a viable alternative to over-provisioning. This combination of powerful individual instances and rapid scaling means you can often achieve high performance through simple architectures.</div><h3 class="MuiTypography-root MuiTypography-h4 mui-hkpafq" id="message-queues">Message Queues</h3><div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">Message queues have transformed from simple task delegation systems into high-performance data highways. Modern systems like Kafka process millions of messages per second with single-digit millisecond latency, while maintaining weeks or months of data. This combination of speed and durability has expanded their role far beyond traditional async processing.</div><div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">Numbers to know:</div><ul class="MuiList-root MuiList-padding mui-sedpvs">
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0">Throughput: Up to 1 million messages/second per broker in modern configurations</div></li>
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0">Latency: 1-5ms end-to-end within a region for optimized setups</div></li>
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0">Message Size: 1KB-10MB efficiently handled</div></li>
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0">Storage: Up to 50TB per broker in advanced configurations</div></li>
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0">Retention: Weeks to months of data, depending on disk capacity and configuration</div></li>
</ul><div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">When to consider sharding:</div><ul class="MuiList-root MuiList-padding mui-sedpvs">
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0">Throughput: Nearing 800k messages/second per broker</div></li>
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0">Partition Count: Approaching 200k per cluster</div></li>
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0">Consumer Lag: Consistently growing, impacting real-time processing</div></li>
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0">Cross-Region Replication: If geographic redundancy is required</div></li>
</ul><div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">The performance characteristics of modern queues challenge traditional system design assumptions. With consistent sub-5ms latencies, you can now use queues within synchronous request flows—getting the benefits of reliable delivery and decoupling without forcing APIs to be async. This speed, combined with practically unlimited storage, means queues can serve as the backbone for event sourcing, real-time analytics, and data integration patterns that previously required specialized systems.</div><h2 class="MuiTypography-root MuiTypography-h3 mui-1rzqq5q" id="cheat-sheet">Cheat Sheet</h2><div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">Here is a one-stop-shop for the numbers you need to know in 2025. These numbers represent typical values for well-tuned systems with specific workloads - your requirements may vary based on workload, hardware, and configuration. Use them as a starting point for capacity planning and system design discussions, not as hard limits. Remember that cloud providers regularly update their offerings, so while I'll try to keep this up to date, it should be treated more as a starting point than a hard limit.</div><div class="MuiTableContainer-root mui-ntrpdu"><table class="MuiTable-root mui-hu1vpi"><thead class="MuiTableHead-root mui-1wbz3t9"><tr class="MuiTableRow-root MuiTableRow-head mui-a1y8t3"><th class="MuiTableCell-root MuiTableCell-head MuiTableCell-sizeSmall mui-1dvcw2j" scope="col">Component</th><th class="MuiTableCell-root MuiTableCell-head MuiTableCell-sizeSmall mui-1dvcw2j" scope="col">Key Metrics</th><th class="MuiTableCell-root MuiTableCell-head MuiTableCell-sizeSmall mui-1dvcw2j" scope="col">Scale Triggers</th></tr></thead><tbody class="MuiTableBody-root mui-1xnox0e"><tr class="MuiTableRow-root mui-a1y8t3"><td class="MuiTableCell-root MuiTableCell-body MuiTableCell-sizeSmall mui-7wgons"><strong>Caching</strong></td><td class="MuiTableCell-root MuiTableCell-body MuiTableCell-sizeSmall mui-7wgons">- ~1 millisecond latency<br>- 100k+ operations/second<br>- Memory-bound (up to 1TB)</td><td class="MuiTableCell-root MuiTableCell-body MuiTableCell-sizeSmall mui-7wgons">- Hit rate &lt; 80%<br>- Latency &gt; 1ms<br>- Memory usage &gt; 80%<br>- Cache churn/thrashing</td></tr><tr class="MuiTableRow-root mui-a1y8t3"><td class="MuiTableCell-root MuiTableCell-body MuiTableCell-sizeSmall mui-7wgons"><strong>Databases</strong></td><td class="MuiTableCell-root MuiTableCell-body MuiTableCell-sizeSmall mui-7wgons">- Up to 50k transactions/second<br>- Sub-5ms read latency (cached)<br>- 64 TiB+ storage capacity</td><td class="MuiTableCell-root MuiTableCell-body MuiTableCell-sizeSmall mui-7wgons">- Write throughput &gt; 10k TPS<br>- Read latency &gt; 5ms uncached<br>- Geographic distribution needs</td></tr><tr class="MuiTableRow-root mui-a1y8t3"><td class="MuiTableCell-root MuiTableCell-body MuiTableCell-sizeSmall mui-7wgons"><strong>App Servers</strong></td><td class="MuiTableCell-root MuiTableCell-body MuiTableCell-sizeSmall mui-7wgons">- 100k+ concurrent connections<br>- 8-64 cores @ 2-4 GHz<br>- 64-512GB RAM standard, up to 2TB</td><td class="MuiTableCell-root MuiTableCell-body MuiTableCell-sizeSmall mui-7wgons">- CPU &gt; 70% utilization<br>- Response latency &gt; SLA<br>- Connections near 15k/instance<br>- Memory &gt; 80%</td></tr><tr class="MuiTableRow-root mui-a1y8t3"><td class="MuiTableCell-root MuiTableCell-body MuiTableCell-sizeSmall mui-7wgons"><strong>Message Queues</strong></td><td class="MuiTableCell-root MuiTableCell-body MuiTableCell-sizeSmall mui-7wgons">- Up to 1 million msgs/sec per broker<br>- Sub-5ms end-to-end latency<br>- Up to 50TB storage</td><td class="MuiTableCell-root MuiTableCell-body MuiTableCell-sizeSmall mui-7wgons">- Throughput near 800k msgs/sec<br>- Partition count ~200k per cluster<br>- Growing consumer lag</td></tr></tbody></table></div><h2 class="MuiTypography-root MuiTypography-h3 mui-1rzqq5q" id="common-mistakes-in-interviews">Common Mistakes In Interviews</h2><h3 class="MuiTypography-root MuiTypography-h4 mui-hkpafq" id="premature-sharding">Premature sharding</h3><div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">The single biggest mistake I see candidates make is assuming sharding is always necessary. They introduce a data model and immediately explain which column they'd shard on. It comes up almost every time with <a class="MuiTypography-root MuiTypography-inherit MuiLink-root MuiLink-underlineHover mui-pvpazu" href="https://hellointerview.com/learn/system-design/problem-breakdowns/yelp" target="_blank" rel="noopener noreferrer" style="color: rgb(99, 115, 129); cursor: pointer; font-weight: 600; text-decoration: underline;">Design Yelp</a> in particular. Here we have 10M businesses, each of which is roughly 1kb of data. This is <span class="MuiBox-root mui-1vu004u">10M * 1kb = 10GB</span> of data! 10x it to account for reviews which we can store in the same database and you're only at <span class="MuiBox-root mui-1vu004u">100GB</span>, why would you shard?</div><div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">The same thing comes up a lot with caches. Take a <a class="MuiTypography-root MuiTypography-inherit MuiLink-root MuiLink-underlineHover mui-pvpazu" href="https://hellointerview.com/learn/system-design/problem-breakdowns/leetcode" target="_blank" rel="noopener noreferrer" style="color: rgb(99, 115, 129); cursor: pointer; font-weight: 600; text-decoration: underline;">LeetCode</a> leaderboard where we have 100k competitions and up to 100k users per competition. We're looking at <span class="MuiBox-root mui-1vu004u">100k * 100k * 36b ID + 4b float rating = 400GB</span>. While even more than what we store on disk with Yelp, this can still fit on a single large cache -- no need to shard!</div><h3 class="MuiTypography-root MuiTypography-h4 mui-hkpafq" id="overestimating-latency">Overestimating latency</h3><div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">I see this most with SSDs. Candidates tend to vastly overestimate the latency additional to query an SSD (Database) for a simple key or row lookup. We're talking 10ms or so. It's fast! Candidates will oftentimes justify adding a caching layer to reduce latency when the simple row lookup is already fast enough -- no need to add additional infrastructure.</div><div class="my-6"><div class="MuiBox-root mui-o9fqh4"><div class="MuiBox-root mui-3t6lyr"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="w-6 h-6 heroicon-sw-2"><path stroke-linecap="round" stroke-linejoin="round" d="M12 9v3.75m-9.303 3.376c-.866 1.5.217 3.374 1.948 3.374h14.71c1.73 0 2.813-1.874 1.948-3.374L13.949 3.378c-.866-1.5-3.032-1.5-3.898 0L2.697 16.126ZM12 15.75h.007v.008H12v-.008Z"></path></svg></div><div class="MuiBox-root mui-79elbk"><div style="overflow: hidden; max-height: 300px;"><div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">Note, this is only for simple row lookups with an index. It is still wise to cache expensive queries.</div></div></div></div></div><h3 class="MuiTypography-root MuiTypography-h4 mui-hkpafq" id="over-engineering-given-a-high-write-throughput">Over-engineering given a high write throughput</h3><div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">Similar to the above, incorrect estimates routinely lead to over-engineering. Imagine we have a system with 5k writes per second. Candidates will often jump to adding a message queue to buffer this "high" write throughput. But they don't need to!</div><div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">Let's put this in perspective. A well-tuned Postgres instance with simple writes can handle 20k+ writes per second. What actually limits write capacity are things like complex transactions spanning multiple tables, write amplification from excessive indexes, writes that trigger expensive cascading updates, or heavy concurrent reads competing with writes. If you're just inserting rows or doing simple updates with proper indexes, there's no need for complex queueing systems at 5k WPS.</div><div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">Message queues become valuable when you need guaranteed delivery in case of downstream failures, event sourcing patterns, handling write spikes above 50k+ WPS, or decoupling producers from consumers. But they add complexity and should be justified by actual requirements. Before reaching for a message queue, consider simpler optimizations like batch writes, optimizing your schema and indexes, using connection pooling effectively, or using async commits for non-critical writes.</div><div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">The core point is to understand your actual write patterns and requirements before adding infrastructure complexity. Modern databases are incredibly capable, and simple solutions often perform better than you might expect.</div><h2 class="MuiTypography-root MuiTypography-h3 mui-1rzqq5q" id="conclusion">Conclusion</h2><div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">Modern hardware capabilities have fundamentally changed the calculus of system design. While distributed systems and horizontal scaling remain necessary for the world's largest applications, many systems can be significantly simpler than what traditional wisdom suggests.</div><div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">Understanding these numbers helps you make better scaling decisions:</div><ul class="MuiList-root MuiList-padding mui-sedpvs">
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0">Single databases can handle terabytes of data</div></li>
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0">Caches can hold entire datasets in memory</div></li>
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0">Message queues are fast enough for synchronous flows (as long as there is no backlog!)</div></li>
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0">Application servers have enough memory for significant local optimization</div></li>
</ul><div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">The key insight isn't that vertical scaling is always the answer – it's knowing where the real limits are. This knowledge helps you avoid premature optimization and build simpler systems that can grow with your needs. In system design interviews, demonstrating this understanding shows that you can balance theoretical knowledge with practical experience – a crucial skill, especially for the more senior levels.</div></div>
</body>
</html>