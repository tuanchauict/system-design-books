<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Web Crawler System Design Interview Guide</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <div><div class="flex flex-col gap-2 md:gap-4"><div class="flex flex-col"><h6 class="MuiTypography-root MuiTypography-h6 mui-zfm63x">Common Problems</h6><h1 class="MuiTypography-root MuiTypography-h2 mui-161snwm">Design a Web Crawler</h1></div><div class="flex flex-col md:flex-row gap-2 md:items-center justify-between"><div class="flex flex-col lg:flex-row gap-4 md:items-center"><a target="_blank" rel="noopener noreferrer" class="flex flex-row gap-2 items-center" href="https://www.linkedin.com/in/evan-king-40072280/" style="text-decoration: none;"><img class="rounded-full" src="https://hellointerview-files.s3.us-west-2.amazonaws.com/public-media/evan-headshot.png" alt="Evan King" width="40" height="40"><div class="flex flex-col"><div class="flex flex-row gap-2 items-center"><p class="MuiTypography-root MuiTypography-body2 mui-ltrqv0">Evan King</p><svg class="MuiSvgIcon-root MuiSvgIcon-fontSizeInherit mui-70s7oy" focusable="false" aria-hidden="true" viewBox="0 0 24 24" data-testid="LinkedInIcon"><path d="M19 3a2 2 0 0 1 2 2v14a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V5a2 2 0 0 1 2-2h14m-.5 15.5v-5.3a3.26 3.26 0 0 0-3.26-3.26c-.85 0-1.84.52-2.32 1.3v-1.11h-2.79v8.37h2.79v-4.93c0-.77.62-1.4 1.39-1.4a1.4 1.4 0 0 1 1.4 1.4v4.93h2.79M6.88 8.56a1.68 1.68 0 0 0 1.68-1.68c0-.93-.75-1.69-1.68-1.69a1.69 1.69 0 0 0-1.69 1.69c0 .93.76 1.68 1.69 1.68m1.39 9.94v-8.37H5.5v8.37h2.77z"></path></svg></div><span class="MuiTypography-root MuiTypography-caption mui-1eozzb8">Ex-Meta Staff Engineer</span></div></a><div class="flex flex-row gap-4 md:gap-8 items-center"><div class="flex flex-row gap-1 items-center" aria-label="Difficulty"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="w-5 h-5 text-gray-500"><path stroke-linecap="round" stroke-linejoin="round" d="M15.362 5.214A8.252 8.252 0 0 1 12 21 8.25 8.25 0 0 1 6.038 7.047 8.287 8.287 0 0 0 9 9.601a8.983 8.983 0 0 1 3.361-6.867 8.21 8.21 0 0 0 3 2.48Z"></path><path stroke-linecap="round" stroke-linejoin="round" d="M12 18a3.75 3.75 0 0 0 .495-7.468 5.99 5.99 0 0 0-1.925 3.547 5.975 5.975 0 0 1-2.133-1.001A3.75 3.75 0 0 0 12 18Z"></path></svg><p class="MuiTypography-root MuiTypography-body2 mui-127w52h">hard</p></div><div class="flex flex-row gap-1 items-center" aria-label="Average time allowed in interview"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="w-5 h-5 text-gray-500"><path stroke-linecap="round" stroke-linejoin="round" d="M12 6v6h4.5m4.5 0a9 9 0 1 1-18 0 9 9 0 0 1 18 0Z"></path></svg><p class="MuiTypography-root MuiTypography-body2 mui-1pb8xyp">35 min</p></div></div></div><a class="MuiButtonBase-root MuiButton-root MuiButton-contained MuiButton-containedPrimary MuiButton-sizeSmall MuiButton-containedSizeSmall MuiButton-colorPrimary MuiButton-disableElevation MuiButton-root MuiButton-contained MuiButton-containedPrimary MuiButton-sizeSmall MuiButton-containedSizeSmall MuiButton-colorPrimary MuiButton-disableElevation mui-1c7cv5a" tabindex="0" href="/practice/system-design/start/web-crawler" target="_blank" rel="noopener noreferrer"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="w-5 h-5 mr-1"><path stroke-linecap="round" stroke-linejoin="round" d="M15.042 21.672 13.684 16.6m0 0-2.51 2.225.569-9.47 5.227 7.917-3.286-.672ZM12 2.25V4.5m5.834.166-1.591 1.591M20.25 10.5H18M7.757 14.743l-1.59 1.59M6 10.5H3.75m4.007-4.243-1.59-1.59"></path></svg>Practice this problem<span class="MuiTouchRipple-root mui-w0pj6f"></span></a></div></div><hr class="MuiDivider-root MuiDivider-fullWidth mui-1rvhejo"></div>
<div class="mb-4"><iframe class="w-full aspect-video" src="https://www.youtube.com/embed/krsuaUp__pM" title="System Design Interview: Design a Web Crawler w/ a Ex-Meta Staff Engineer" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<h2 class="MuiTypography-root MuiTypography-h3 mui-1rzqq5q" id="understanding-the-problem">Understanding the Problem</h2>
<div class="my-6"><div class="MuiBox-root mui-1fz7ihe"><div class="MuiBox-root mui-79elbk"><div style="overflow: hidden; max-height: 300px;"><div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag"><strong>üï∏Ô∏è What is a Web Crawler</strong>
A web crawler is a program that automatically traverses the web by downloading web pages and following links from one page to another. It is used to index the web for search engines, collect data for research, or monitor websites for changes.</div></div></div></div></div>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">Depending on the interview, the output of the traversed web pages may be used for different purposes. This can have some consequences on the overall design. For example, a search engine would need to index the data and rank it (using PageRank or other algorithms), while a company like OpenAI would dump the raw text from the pages into a database to be used to train LLMs (Large Language Models). Regardless of the use case, the interview is likely to focus on the crawling task‚Äîhow can we efficiently crawl the web, extract the necessary data, and store it in a way that is easily accessible?</div>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">For our purposes, we'll design a web crawler whose goal is to extract text data from the web to train an LLM. This could be used by a company like OpenAI to train their GPT-4 model, Google to train Gemini, Meta to train LLaMA, etc.</div>
<h3 class="MuiTypography-root MuiTypography-h4 mui-hkpafq" id="functional-requirements"><a class="MuiTypography-root MuiTypography-inherit MuiLink-root MuiLink-underlineHover mui-pvpazu" href="https://www.hellointerview.com/learn/system-design/in-a-hurry/delivery#1-functional-requirements-1" target="_blank" rel="noopener noreferrer" style="color: rgb(99, 115, 129); cursor: pointer; font-weight: 600; text-decoration: underline;">Functional Requirements</a></h3>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag"><strong>Core Requirements</strong></div>
<ol style="list-style: outside decimal;">
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0">Crawl the web starting from a given set of seed URLs.</div></li>
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0">Extract text data from each web page and store the text for later processing.</div></li>
</ol>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag"><strong>Below the line (out of scope)</strong></div>
<ol style="list-style: outside decimal;">
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0">The actual processing of the text data (e.g., training an LLM).</div></li>
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0">Handling of non-text data (e.g., images, videos, etc.).</div></li>
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0">Handling of dynamic content (e.g., JavaScript-rendered pages).</div></li>
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0">Handling of authentication (e.g., login-required pages).</div></li>
</ol>
<div class="my-6"><div class="MuiBox-root mui-o9fqh4"><div class="MuiBox-root mui-3t6lyr"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="w-6 h-6 heroicon-sw-2"><path stroke-linecap="round" stroke-linejoin="round" d="M12 9v3.75m-9.303 3.376c-.866 1.5.217 3.374 1.948 3.374h14.71c1.73 0 2.813-1.874 1.948-3.374L13.949 3.378c-.866-1.5-3.032-1.5-3.898 0L2.697 16.126ZM12 15.75h.007v.008H12v-.008Z"></path></svg></div><div class="MuiBox-root mui-79elbk"><div style="overflow: hidden; max-height: 300px;"><div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">It's not possible to scrape the entire internet. Instead, we are going to scrape the vast majority of the web. Many small sites exist in the dark corners of the internet that we will not be able to reach. It may be worth clarifying this with your interviewer, but it's a general assumption of web crawling that you can't reach every page on the web.</div></div></div></div></div>
<h3 class="MuiTypography-root MuiTypography-h4 mui-hkpafq" id="non-functional-requirements"><a class="MuiTypography-root MuiTypography-inherit MuiLink-root MuiLink-underlineHover mui-pvpazu" href="https://www.hellointerview.com/learn/system-design/in-a-hurry/delivery#2-non-functional-requirements-1" target="_blank" rel="noopener noreferrer" style="color: rgb(99, 115, 129); cursor: pointer; font-weight: 600; text-decoration: underline;">Non-Functional Requirements</a></h3>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">Before we jump into our non-functional requirements, it's important to ask your interviewer about the scale of the system. For this design in particular, the scale will have a large impact on the database design and the overall architecture.</div>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">We'll assume there are 10B pages on the web, with an average size of 2MB. We are also going to say that the company needs this data to be available for training 5 days after you start crawling.</div>
<div class="my-6"><div class="MuiBox-root mui-1147lff"><div class="MuiBox-root mui-zvu67g"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="w-6 h-6 heroicon-sw-2"><path stroke-linecap="round" stroke-linejoin="round" d="M12 18v-5.25m0 0a6.01 6.01 0 0 0 1.5-.189m-1.5.189a6.01 6.01 0 0 1-1.5-.189m3.75 7.478a12.06 12.06 0 0 1-4.5 0m3.75 2.383a14.406 14.406 0 0 1-3 0M14.25 18v-.192c0-.983.658-1.823 1.508-2.316a7.5 7.5 0 1 0-7.517 0c.85.493 1.509 1.333 1.509 2.316V18"></path></svg></div><div class="MuiBox-root mui-79elbk"><div style="overflow: hidden; max-height: 300px;"><div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">It's commonly advised to start with back-of-the-envelope (BOE) calculations. However, I recommend delaying these calculations until they are necessary for solving a specific problem. This approach avoids unnecessary computations and focuses your efforts on aspects that directly impact your solution. You'll find examples of appropriate moments for estimations in our detailed discussions later. Regardless of what approach you take, just make sure to communicate with your interviewer so that you're on the same page.</div></div></div></div></div>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">With that in mind, let's document the non-functional requirements:</div>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag"><strong>Core Requirements</strong></div>
<ol style="list-style: outside decimal;">
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0">Fault tolerance to handle failures gracefully and resume crawling without losing progress.</div></li>
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0">Politeness to adhere to <span class="MuiBox-root mui-1vu004u">robots.txt</span> and not overload website servers inappropriately.</div></li>
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0">Efficiency to crawl the web in under 5 days.</div></li>
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0">Scalability to handle 10B pages.</div></li>
</ol>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag"><strong>Below the line (out of scope)</strong></div>
<ol style="list-style: outside decimal;">
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0">Security to protect the system from malicious actors.</div></li>
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0">Cost to operate the system within budget constraints.</div></li>
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0">Compliance to adhere to legal requirements and privacy regulations.</div></li>
</ol>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">Here's how it might look on your whiteboard:</div>
<div class="my-4 flex-col w-full undefined"><div class="MuiBox-root mui-10khgmf" style="cursor: pointer;"><div class="MuiGrid-root MuiGrid-container MuiGrid-direction-xs-column mui-1tdxmx0"><div class="MuiGrid-root MuiGrid-item mui-tolxbf"><div class="relative w-full"><button class="MuiButtonBase-root MuiIconButton-root MuiIconButton-sizeSmall mui-wksd04" tabindex="0" type="button" aria-label="zoom-in"><svg class="MuiSvgIcon-root MuiSvgIcon-fontSizeMedium mui-10dohqv" focusable="false" aria-hidden="true" viewBox="0 0 24 24" data-testid="ZoomInIcon"><path d="M15.5 14h-.79l-.28-.27C15.41 12.59 16 11.11 16 9.5 16 5.91 13.09 3 9.5 3S3 5.91 3 9.5 5.91 16 9.5 16c1.61 0 3.09-.59 4.23-1.57l.27.28v.79l5 4.99L20.49 19zm-6 0C7.01 14 5 11.99 5 9.5S7.01 5 9.5 5 14 7.01 14 9.5 11.99 14 9.5 14"></path><path d="M12 10h-2v2H9v-2H7V9h2V7h1v2h2z"></path></svg><span class="MuiTouchRipple-root mui-w0pj6f"></span></button><div class="w-full"><img class="w-full max-w-full max-h-full" src="https://d248djf5mc6iku.cloudfront.net/excalidraw/47df9913bc05125cf13ba6d1dbd6ab1d" alt="Requirements"></div></div></div><div class="MuiGrid-root MuiGrid-item mui-1wxaqej"><span class="MuiTypography-root MuiTypography-caption mui-17cupi8">Requirements</span></div></div></div></div>
<h2 class="MuiTypography-root MuiTypography-h3 mui-1rzqq5q" id="the-set-up">The Set Up</h2>
<h3 class="MuiTypography-root MuiTypography-h4 mui-hkpafq" id="planning-the-approach">Planning the Approach</h3>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">Given this system isn't a user-facing system, we'll instead focus on the abstract interface it has with the outside world and break down the data flow before proceeding to the high-level design. This will give us a good high-level picture of how the pieces should fit together which we can use as scaffolding for our design.</div>
<h3 class="MuiTypography-root MuiTypography-h4 mui-hkpafq" id="api-or-system-interface"><a class="MuiTypography-root MuiTypography-inherit MuiLink-root MuiLink-underlineHover mui-pvpazu" href="https://www.hellointerview.com/learn/system-design/in-a-hurry/delivery#system-interface-2-minutes" target="_blank" rel="noopener noreferrer" style="color: rgb(99, 115, 129); cursor: pointer; font-weight: 600; text-decoration: underline;">API or System Interface</a></h3>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">For data processing system design questions like this one, it helps to start by defining the system's interface. This includes clearly outline what data the system receives and what it outputs, establishing a clear boundary of the system‚Äôs functionality.</div>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag"><strong>System Interface</strong></div>
<ol style="list-style: outside decimal;">
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0"><strong>Input</strong>: Seed URLs to start crawling from.</div></li>
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0"><strong>Output</strong>: Text data extracted from web pages.</div></li>
</ol>
<h3 class="MuiTypography-root MuiTypography-h4 mui-hkpafq" id="data-flow"><a class="MuiTypography-root MuiTypography-inherit MuiLink-root MuiLink-underlineHover mui-pvpazu" href="/learn/system-design/in-a-hurry/delivery#optional-data-flow-5-minutes" target="_blank" rel="noopener noreferrer" style="color: rgb(99, 115, 129); cursor: pointer; font-weight: 600; text-decoration: underline;">Data Flow</a></h3>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">The data flow is the sequential series of steps we'll cover in order to get from the inputs to our system to the outputs. Clarifying this flow early will help to align with our interviewer before the high-level design. For our crawler, we need to perform a sequence of steps before the page can be crawled:</div>
<ol style="list-style: outside decimal;">
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0">Take seed URL from frontier and request IP from DNS</div></li>
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0">Fetch HTML from external server using IP</div></li>
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0">Extract text data from the HTML.</div></li>
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0">Store the text data in a database.</div></li>
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0">Extract any linked URLs from the web pages and add them to the list of URLs to crawl.</div></li>
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0">Repeat steps 1-5 until all URLs have been crawled.</div></li>
</ol>
<div class="my-6"><div class="MuiBox-root mui-1ygn9bx"><div class="MuiBox-root mui-14185gn"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="w-6 h-6 heroicon-sw-2"><path stroke-linecap="round" stroke-linejoin="round" d="M12 9v3.75m9-.75a9 9 0 1 1-18 0 9 9 0 0 1 18 0Zm-9 3.75h.008v.008H12v-.008Z"></path></svg></div><div class="MuiBox-root mui-79elbk"><div style="overflow: hidden; max-height: 300px;"><div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">Note that this is simple, we will improve upon as we go, but it's important to start simple and build up from there.</div></div></div></div></div>
<h2 class="MuiTypography-root MuiTypography-h3 mui-1rzqq5q" id="high-level-design"><a class="MuiTypography-root MuiTypography-inherit MuiLink-root MuiLink-underlineHover mui-pvpazu" href="https://www.hellointerview.com/learn/system-design/in-a-hurry/delivery#high-level-design-10-15-minutes-1" target="_blank" rel="noopener noreferrer" style="color: rgb(99, 115, 129); cursor: pointer; font-weight: 600; text-decoration: underline;">High-Level Design</a></h2>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">For our high-level design, we will focus on getting a simple system up and running that satisfies our core functional requirements by simply following the data flow we outlined above. We will improve upon this design in the next section.</div>
<div class="my-4 flex-col w-full undefined"><div class="MuiBox-root mui-10khgmf" style="cursor: pointer;"><div class="MuiGrid-root MuiGrid-container MuiGrid-direction-xs-column mui-1tdxmx0"><div class="MuiGrid-root MuiGrid-item mui-tolxbf"><div class="relative w-full"><button class="MuiButtonBase-root MuiIconButton-root MuiIconButton-sizeSmall mui-wksd04" tabindex="0" type="button" aria-label="zoom-in"><svg class="MuiSvgIcon-root MuiSvgIcon-fontSizeMedium mui-10dohqv" focusable="false" aria-hidden="true" viewBox="0 0 24 24" data-testid="ZoomInIcon"><path d="M15.5 14h-.79l-.28-.27C15.41 12.59 16 11.11 16 9.5 16 5.91 13.09 3 9.5 3S3 5.91 3 9.5 5.91 16 9.5 16c1.61 0 3.09-.59 4.23-1.57l.27.28v.79l5 4.99L20.49 19zm-6 0C7.01 14 5 11.99 5 9.5S7.01 5 9.5 5 14 7.01 14 9.5 11.99 14 9.5 14"></path><path d="M12 10h-2v2H9v-2H7V9h2V7h1v2h2z"></path></svg><span class="MuiTouchRipple-root mui-w0pj6f"></span></button><div class="w-full"><img class="w-full max-w-full max-h-full" src="https://d248djf5mc6iku.cloudfront.net/excalidraw/e990335f1e139dcbb47132177e7339a1" alt="Requirements"></div></div></div><div class="MuiGrid-root MuiGrid-item mui-1wxaqej"><span class="MuiTypography-root MuiTypography-caption mui-17cupi8">Requirements</span></div></div></div></div>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">The core components of our high-level design are:</div>
<ol style="list-style: outside decimal;">
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0"><strong>Frontier Queue</strong>: The queue of URLs we need to crawl. We will start with a set of seed URLs and add new URLs as we crawl the web. The technology used could be something like Kafka, Redis, or SQS. We'll decide on the technology later.</div></li>
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0"><strong>Crawler</strong>: Fetches web pages, extracts text data, and extracts new URLs to add to the frontier queue. In the next section we'll talk about how to scale this component to handle the 10B pages we need to crawl.</div></li>
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0"><strong>DNS</strong>: Resolves domain names to IP addresses so that the crawler can fetch the web pages. There are interesting discussions to be had about how to cache DNS lookups, handle DNS failures, and ensure that we are not overloading DNS servers. Again, more on this later.</div></li>
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0"><strong>Webpage</strong>: TThe external server that hosts the web pages we are crawling. We'll fetch the HTML from these servers and extract the text data.</div></li>
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0"><strong>S3 Text Data</strong>: This is where we'll store the text data we extract from the web pages. We choose S3 as our blob storage because it is highly scalable and durable. It is designed to store large amounts of data cheaply. Other hosted storage solutions like Google Cloud Storage or Azure Blob Storage could also be used.</div></li>
</ol>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">The dotted rectangle represents the boundary of our system. Everything inside the rectangle is part of our system, while everything outside is external to our system, like the web pages we are crawling.</div>
<div class="my-6"><div class="MuiBox-root mui-1147lff"><div class="MuiBox-root mui-zvu67g"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="w-6 h-6 heroicon-sw-2"><path stroke-linecap="round" stroke-linejoin="round" d="M12 18v-5.25m0 0a6.01 6.01 0 0 0 1.5-.189m-1.5.189a6.01 6.01 0 0 1-1.5-.189m3.75 7.478a12.06 12.06 0 0 1-4.5 0m3.75 2.383a14.406 14.406 0 0 1-3 0M14.25 18v-.192c0-.983.658-1.823 1.508-2.316a7.5 7.5 0 1 0-7.517 0c.85.493 1.509 1.333 1.509 2.316V18"></path></svg></div><div class="MuiBox-root mui-79elbk"><div style="overflow: hidden; max-height: 300px;"><div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">It's wise to ask your interviewer about the seed URLs. Are they provided to you, or do you need to come up with them yourself? In almost all cases, the seed URLs will be provided to you. But this question shows that you are thinking holistically about the problem. If they're not, you can discuss a few strategies for coming up with them, like starting with the most popular search engines, news sites, social media platforms, and/or web directories.</div></div></div></div></div>
<h2 class="MuiTypography-root MuiTypography-h3 mui-1rzqq5q" id="potential-deep-dives"><a class="MuiTypography-root MuiTypography-inherit MuiLink-root MuiLink-underlineHover mui-pvpazu" href="https://www.hellointerview.com/learn/system-design/in-a-hurry/delivery#deep-dives-10-minutes-1" target="_blank" rel="noopener noreferrer" style="color: rgb(99, 115, 129); cursor: pointer; font-weight: 600; text-decoration: underline;">Potential Deep Dives</a></h2>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">That should have been relatively straightforward so far. Now for the fun part. We are going to go 1-by-1 through our non-functional requirements and discuss how we can improve our design to meet them.</div>
<div class="my-6"><div class="MuiBox-root mui-1147lff"><div class="MuiBox-root mui-zvu67g"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="w-6 h-6 heroicon-sw-2"><path stroke-linecap="round" stroke-linejoin="round" d="M12 18v-5.25m0 0a6.01 6.01 0 0 0 1.5-.189m-1.5.189a6.01 6.01 0 0 1-1.5-.189m3.75 7.478a12.06 12.06 0 0 1-4.5 0m3.75 2.383a14.406 14.406 0 0 1-3 0M14.25 18v-.192c0-.983.658-1.823 1.508-2.316a7.5 7.5 0 1 0-7.517 0c.85.493 1.509 1.333 1.509 2.316V18"></path></svg></div><div class="MuiBox-root mui-79elbk"><div style="overflow: hidden; max-height: 300px;"><div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">This is why defining good non-functional requirements is so important -- especially for more senior candidates! So often I see candidates rush through the requirements and then look at me, the interviewer, wide eyed, unsure of what to do next after they have a simple design. If you've taken your time to define quality non-functional requirements, then you shouldn't run out of things to talk about until your system has met all functional and non-functional requirements, at which point, you've likely passed the interview!</div></div></div></div></div>
<h3 class="MuiTypography-root MuiTypography-h4 mui-hkpafq" id="1-how-can-we-ensure-we-are-fault-tolerant-and-dont-lose-progress">1) How can we ensure we are fault tolerant and don't lose progress?</h3>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">The first thing we should notice is that our crawler service is doing a lot. It's hitting DNS, fetching web pages, extracting text data, and extracting new URLs to add to the frontier queue. When we introduce politeness and efficiency, we'll find that it ends up doing even more. While the server can handle all of these tasks, it's not ideal from a fault tolerance perspective. If there is a failure in any single task, all progress will be lost.</div>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">Fetching web pages is the most likely task to fail. The internet is a messy place and there are many reasons why a fetch might fail. The server might be down, the connection might be slow, the page might be too large, etc.</div>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">To handle this, we should break the crawler service into smaller, pipelined stages. This way, if there is a failure in any stage, we can retry that stage without losing progress on the rest of the data. It also allows us to scale each stage independently and optimize each stage for its specific task.</div>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">Here's how we might break the crawler service into stages:</div>
<ol style="list-style: outside decimal;">
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0"><strong>URL Fetcher</strong>: This stage fetches the HTML of the web page from the external server. If there is a failure, we can retry the fetch without losing progress on the rest of the data. We will store the raw HTML in blob storage for later processing.</div></li>
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0"><strong>Text &amp; URL Extraction</strong>: This stage extracts the text data from the HTML and extracts any linked URLs to add to the frontier queue. There is an argument that text extraction and URL extraction should be separate stages, but these tasks are both simple and can be done in parallel without much overhead so I'd prefer to simplify the design and combine them into a single stage.</div></li>
</ol>
<div class="my-6"><div class="MuiBox-root mui-1147lff"><div class="MuiBox-root mui-zvu67g"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="w-6 h-6 heroicon-sw-2"><path stroke-linecap="round" stroke-linejoin="round" d="M12 18v-5.25m0 0a6.01 6.01 0 0 0 1.5-.189m-1.5.189a6.01 6.01 0 0 1-1.5-.189m3.75 7.478a12.06 12.06 0 0 1-4.5 0m3.75 2.383a14.406 14.406 0 0 1-3 0M14.25 18v-.192c0-.983.658-1.823 1.508-2.316a7.5 7.5 0 1 0-7.517 0c.85.493 1.509 1.333 1.509 2.316V18"></path></svg></div><div class="MuiBox-root mui-79elbk"><div style="overflow: hidden; max-height: 300px;"><div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">If you get a data processing question like this, your first thought should be to break the system down into smaller, pipelined stages. Pipelining allows you to isolate failures to a single stage and retry that stage without losing progress on the rest of the data. It also allows us to scale each stage independently and optimize each stage for its specific task.</div></div></div></div></div>
<div class="my-4 flex-col w-full undefined"><div class="MuiBox-root mui-10khgmf" style="cursor: pointer;"><div class="MuiGrid-root MuiGrid-container MuiGrid-direction-xs-column mui-1tdxmx0"><div class="MuiGrid-root MuiGrid-item mui-tolxbf"><div class="relative w-full"><button class="MuiButtonBase-root MuiIconButton-root MuiIconButton-sizeSmall mui-wksd04" tabindex="0" type="button" aria-label="zoom-in"><svg class="MuiSvgIcon-root MuiSvgIcon-fontSizeMedium mui-10dohqv" focusable="false" aria-hidden="true" viewBox="0 0 24 24" data-testid="ZoomInIcon"><path d="M15.5 14h-.79l-.28-.27C15.41 12.59 16 11.11 16 9.5 16 5.91 13.09 3 9.5 3S3 5.91 3 9.5 5.91 16 9.5 16c1.61 0 3.09-.59 4.23-1.57l.27.28v.79l5 4.99L20.49 19zm-6 0C7.01 14 5 11.99 5 9.5S7.01 5 9.5 5 14 7.01 14 9.5 11.99 14 9.5 14"></path><path d="M12 10h-2v2H9v-2H7V9h2V7h1v2h2z"></path></svg><span class="MuiTouchRipple-root mui-w0pj6f"></span></button><div class="w-full"><img class="w-full max-w-full max-h-full" src="https://d248djf5mc6iku.cloudfront.net/excalidraw/96a04b77ade7917194fe4f9bbd8afb11" alt="Multi-Stage Pipeline"></div></div></div><div class="MuiGrid-root MuiGrid-item mui-1wxaqej"><span class="MuiTypography-root MuiTypography-caption mui-17cupi8">Multi-Stage Pipeline</span></div></div></div></div>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">In order to make this work, we need to add some additional state. We'll add a Metadata DB (DynamoDB is fine here. PostgreSQL/MySQL could also work) with a table for URLs that have been fetched and processed. As a starting point, this will store the link to the blob storage where the HTML is stored and the link to the blob storage where the text data is stored. This is important because it is an anti-pattern to store the raw HTML in the queue itself. Queues are not optimized for large payloads and it would be expensive to store the HTML in the queue. Instead, the queue message will just be the id of the URL in the Metadata DB.</div>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">Importantly, this not only helps with fault tolerance but also allows us to be robust to changing requirements. You can imagine that the ML team consuming this data wants to change the text extraction process. A simple example could be including image alt text in the extracted text. If we have a separate stage for text extraction, we can easily swap out the text extraction function without needing to redo the expensive part of fetching the web pages.</div>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag"><strong>What about if we fail to fetch a URL?</strong></div>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">As mentioned, URL fetching is clearly the most likely task to fail. Many websites may no longer exist, may have moved, or may be down. Others may just be slow or experiencing momentary down time. To confirm, we'll want to retry on failures. Here is how we might handle this:</div>
<div class="my-6 flex flex-col gap-4"><div class="MuiPaper-root MuiPaper-elevation MuiPaper-rounded MuiPaper-elevation0 MuiAccordion-root MuiAccordion-rounded MuiAccordion-gutters mui-ifi55z"><div class="MuiButtonBase-root MuiAccordionSummary-root MuiAccordionSummary-gutters mui-1ev8i4f" tabindex="0" role="button" aria-expanded="false" aria-controls="panel1bh-content" id="panel1bh-header"><div class="MuiAccordionSummary-content MuiAccordionSummary-contentGutters mui-l0jafl"><p class="MuiTypography-root MuiTypography-body1 mui-h8owmt">Bad Solution: In Memory Timer</p></div><div class="MuiAccordionSummary-expandIconWrapper mui-awtdfi"><svg class="MuiSvgIcon-root MuiSvgIcon-fontSizeMedium mui-10dohqv" focusable="false" aria-hidden="true" viewBox="0 0 24 24" data-testid="ExpandMoreIcon"><path d="M16.59 8.59 12 13.17 7.41 8.59 6 10l6 6 6-6z"></path></svg></div></div><div class="MuiCollapse-root MuiCollapse-vertical MuiCollapse-hidden mui-a0y2e3" style="min-height: 0px;"><div class="MuiCollapse-wrapper MuiCollapse-vertical mui-hboir5"><div class="MuiCollapse-wrapperInner MuiCollapse-vertical mui-8atqhb"><div aria-labelledby="panel1bh-header" id="panel1bh-content" role="region" class="MuiAccordion-region"><div class="MuiAccordionDetails-root mui-u7qq7e"><h6 class="MuiTypography-root MuiTypography-body1 mui-1quhbks" id="approach">Approach</h6><div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">The easiest (and worst) thing we could do is to just wait a few seconds using an in-memory timer and try again.</div><h6 class="MuiTypography-root MuiTypography-body1 mui-1quhbks" id="challenges">Challenges</h6><div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">Beyond any issues with politeness, which we will address next, this isn't robust because if a crawler were to go down, we would lose the timer. It is also very likely that the fetch won't succeed in just a few more seconds. We'll need to be smarter and implement some sort of exponential backoff.</div></div></div></div></div></div></div><div class="MuiPaper-root MuiPaper-elevation MuiPaper-rounded MuiPaper-elevation0 MuiAccordion-root MuiAccordion-rounded MuiAccordion-gutters mui-nhbct3"><div class="MuiButtonBase-root MuiAccordionSummary-root MuiAccordionSummary-gutters mui-guv1gb" tabindex="0" role="button" aria-expanded="false" aria-controls="panel1bh-content" id="panel1bh-header"><div class="MuiAccordionSummary-content MuiAccordionSummary-contentGutters mui-l0jafl"><p class="MuiTypography-root MuiTypography-body1 mui-h8owmt">Good Solution: Kafka with Manual Exponential Backoff</p></div><div class="MuiAccordionSummary-expandIconWrapper mui-awtdfi"><svg class="MuiSvgIcon-root MuiSvgIcon-fontSizeMedium mui-10dohqv" focusable="false" aria-hidden="true" viewBox="0 0 24 24" data-testid="ExpandMoreIcon"><path d="M16.59 8.59 12 13.17 7.41 8.59 6 10l6 6 6-6z"></path></svg></div></div><div class="MuiCollapse-root MuiCollapse-vertical MuiCollapse-hidden mui-a0y2e3" style="min-height: 0px;"><div class="MuiCollapse-wrapper MuiCollapse-vertical mui-hboir5"><div class="MuiCollapse-wrapperInner MuiCollapse-vertical mui-8atqhb"><div aria-labelledby="panel1bh-header" id="panel1bh-content" role="region" class="MuiAccordion-region"><div class="MuiAccordionDetails-root mui-u7qq7e"><h6 class="MuiTypography-root MuiTypography-body1 mui-1quhbks" id="approach-1">Approach</h6><div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">Kafka does not support retries out of the box, but we could implement them ourselves. We could have a separate topic for failed URLs and a separate service that reads from this topic and retries the fetch with exponential backoff. In order to know how much to backoff, we could store the time that the next fetch should occur in the message itself. When a consumer reads a message, it will check the time and if it is in the future, it will wait until that time to retry the fetch.</div><h6 class="MuiTypography-root MuiTypography-body1 mui-1quhbks" id="challenges-1">Challenges</h6><div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">This can work, it's just complex to implement and maintain. Fortunately for us, there are services that do this for us out of the box.</div></div></div></div></div></div></div><div class="MuiPaper-root MuiPaper-elevation MuiPaper-rounded MuiPaper-elevation0 MuiAccordion-root MuiAccordion-rounded MuiAccordion-gutters mui-11r69q9"><div class="MuiButtonBase-root MuiAccordionSummary-root MuiAccordionSummary-gutters mui-3ujfba" tabindex="0" role="button" aria-expanded="false" aria-controls="panel1bh-content" id="panel1bh-header"><div class="MuiAccordionSummary-content MuiAccordionSummary-contentGutters mui-l0jafl"><p class="MuiTypography-root MuiTypography-body1 mui-h8owmt">Great Solution: SQS with Exponential Backoff</p></div><div class="MuiAccordionSummary-expandIconWrapper mui-awtdfi"><svg class="MuiSvgIcon-root MuiSvgIcon-fontSizeMedium mui-10dohqv" focusable="false" aria-hidden="true" viewBox="0 0 24 24" data-testid="ExpandMoreIcon"><path d="M16.59 8.59 12 13.17 7.41 8.59 6 10l6 6 6-6z"></path></svg></div></div><div class="MuiCollapse-root MuiCollapse-vertical MuiCollapse-hidden mui-a0y2e3" style="min-height: 0px;"><div class="MuiCollapse-wrapper MuiCollapse-vertical mui-hboir5"><div class="MuiCollapse-wrapperInner MuiCollapse-vertical mui-8atqhb"><div aria-labelledby="panel1bh-header" id="panel1bh-content" role="region" class="MuiAccordion-region"><div class="MuiAccordionDetails-root mui-u7qq7e"><h6 class="MuiTypography-root MuiTypography-body1 mui-1quhbks" id="approach-2">Approach</h6><div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">SQS supports retries with configurable exponential backoff out of the box -- convenient! No need to implement our own retry logic. Initially, messages that fail to process are retried once per the visibility timeout, with the default being 30 seconds. The visibility timeout increases exponentially after each retry attempt‚Äî30 seconds, 2 minutes, 5 minutes, and up to 15 minutes. This strategy helps to manage message processing more efficiently without overwhelming the system.</div><h6 class="MuiTypography-root MuiTypography-body1 mui-1quhbks" id="challenges-2">Challenges</h6><div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">We don't want to retry indefinitely. That would be silly.</div><div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">To prevent excessive delays, it is common to cap the exponential backoff at a maximum value. After a certain number of failures, as determined by the <span class="MuiBox-root mui-1vu004u">ApproximateReceiveCount</span>, the message is moved to a dead-letter queue (DLQ). At this stage, the message is considered unprocessable. For our purposes, we'll consider the site offline, and thus unscrapable, after 5 retries.</div></div></div></div></div></div></div></div>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag"><strong>What happens if a crawler goes down?</strong></div>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">The answer is simple: we spin up a new one. We'll just have to make sure that the half-finished URL is not lost.</div>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">Good news is the URL will stay in the queue until it is confirmed to have been fetched by a crawler and the HTML is stored in blob storage. This way, if a crawler goes down, the URL will be picked up by another crawler and the process will continue. The actual mechanism for accomplishing this is different per technology. I'll outline, at a very high level, how two popular technologies, Kafka and SQS, might handle this:</div>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">Apache Kafka:</div>
<ul class="MuiList-root MuiList-padding mui-sedpvs">
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0">Kafka retains messages in a log and does not remove them even after they are read. Crawlers track their progress via offsets, which are not updated in Kafka until the URL is successfully fetched and processed. If a crawler fails, the next one picks up right where the last one left off, ensuring no data is lost.</div></li>
</ul>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">SQS:</div>
<ul class="MuiList-root MuiList-padding mui-sedpvs">
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0">With SQS, messages remain in the queue until they are explicitly deleted. A visibility timeout hides a message from other crawlers once it's fetched. If the crawler fails before confirming successful processing, the message will automatically become visible again after the timeout expires, allowing another crawler to attempt the fetch. On the other hand, once the HTML is stored in blob storage, the crawler will delete the message from the queue, ensuring it is not processed again.</div></li>
</ul>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">Of course, the same applies if a parsing worker goes down. The URL will remain in the queue until it is confirmed to have been processed and the text data is stored in blob storage.</div>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">Given SQS's built-in support for retries and exponential backoff and the ease with which visibility timeouts can be configured, <strong>we'll use SQS for our system</strong>.</div>
<div class="my-4 flex-col w-full undefined"><div class="MuiBox-root mui-10khgmf" style="cursor: pointer;"><div class="MuiGrid-root MuiGrid-container MuiGrid-direction-xs-column mui-1tdxmx0"><div class="MuiGrid-root MuiGrid-item mui-tolxbf"><div class="relative w-full"><button class="MuiButtonBase-root MuiIconButton-root MuiIconButton-sizeSmall mui-wksd04" tabindex="0" type="button" aria-label="zoom-in"><svg class="MuiSvgIcon-root MuiSvgIcon-fontSizeMedium mui-10dohqv" focusable="false" aria-hidden="true" viewBox="0 0 24 24" data-testid="ZoomInIcon"><path d="M15.5 14h-.79l-.28-.27C15.41 12.59 16 11.11 16 9.5 16 5.91 13.09 3 9.5 3S3 5.91 3 9.5 5.91 16 9.5 16c1.61 0 3.09-.59 4.23-1.57l.27.28v.79l5 4.99L20.49 19zm-6 0C7.01 14 5 11.99 5 9.5S7.01 5 9.5 5 14 7.01 14 9.5 11.99 14 9.5 14"></path><path d="M12 10h-2v2H9v-2H7V9h2V7h1v2h2z"></path></svg><span class="MuiTouchRipple-root mui-w0pj6f"></span></button><div class="w-full"><img class="w-full max-w-full max-h-full" src="https://d248djf5mc6iku.cloudfront.net/excalidraw/0e13e43cae1da95b9b71928588eeb258" alt="SQS with Retry and DLQ"></div></div></div><div class="MuiGrid-root MuiGrid-item mui-1wxaqej"><span class="MuiTypography-root MuiTypography-caption mui-17cupi8">SQS with Retry and DLQ</span></div></div></div></div>
<div class="my-6"><div class="MuiBox-root mui-o9fqh4"><div class="MuiBox-root mui-3t6lyr"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="w-6 h-6 heroicon-sw-2"><path stroke-linecap="round" stroke-linejoin="round" d="M12 9v3.75m-9.303 3.376c-.866 1.5.217 3.374 1.948 3.374h14.71c1.73 0 2.813-1.874 1.948-3.374L13.949 3.378c-.866-1.5-3.032-1.5-3.898 0L2.697 16.126ZM12 15.75h.007v.008H12v-.008Z"></path></svg></div><div class="MuiBox-root mui-79elbk"><div style="overflow: hidden; max-height: 300px;"><div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">When it comes to choosing a technology, there is usually no right or wrong answer. It's all about trade-offs and your ability to justify your decision. Additionally, it's totally reasonable that you would not know the specifics of how Kafka or SQS handle retries. If that's the case, this may not be a place where you choose to go deep.</div></div></div></div></div>
<h3 class="MuiTypography-root MuiTypography-h4 mui-hkpafq" id="2-how-can-we-ensure-politeness-and-adhere-to-robotstxt">2) How can we ensure politeness and adhere to robots.txt?</h3>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">First thing first, what is politeness and what is a <span class="MuiBox-root mui-1vu004u">robots.txt</span> file?</div>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">Politeness refers to being respectful with the resources of the websites we are crawling. This involves ensuring that our crawling activity does not disrupt the normal function of the site by overloading its servers, respecting the website's bandwidth, and adhering to any specific restrictions or rules set by the site administrators.</div>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag"><span class="MuiBox-root mui-1vu004u">robots.txt</span> is a file that websites use to communicate with web crawlers. It tells crawlers which pages they are allowed to crawl and which pages they are not. It also tells crawlers how frequently they can crawl the site. An example of a <span class="MuiBox-root mui-1vu004u">robots.txt</span> file might look like this:</div>
<pre><div class="MuiBox-root mui-xnilmx"><div class="MuiBox-root mui-v2ritd"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="w-4 h-4  cursor-pointer" aria-label="Copy"><path stroke-linecap="round" stroke-linejoin="round" d="M15.666 3.888A2.25 2.25 0 0 0 13.5 2.25h-3c-1.03 0-1.9.693-2.166 1.638m7.332 0c.055.194.084.4.084.612v0a.75.75 0 0 1-.75.75H9a.75.75 0 0 1-.75-.75v0c0-.212.03-.418.084-.612m7.332 0c.646.049 1.288.11 1.927.184 1.1.128 1.907 1.077 1.907 2.185V19.5a2.25 2.25 0 0 1-2.25 2.25H6.75A2.25 2.25 0 0 1 4.5 19.5V6.257c0-1.108.806-2.057 1.907-2.185a48.208 48.208 0 0 1 1.927-.184"></path></svg></div><div style="background: rgb(250, 250, 250); color: rgb(56, 58, 66); font-family: &quot;Fira Code&quot;, &quot;Fira Mono&quot;, Menlo, Consolas, &quot;DejaVu Sans Mono&quot;, monospace; direction: ltr; text-align: left; white-space: pre; word-spacing: normal; word-break: normal; line-height: 1.5; tab-size: 2; hyphens: none; padding: 1em; margin: 0px; overflow: auto; border-radius: 0.375rem; border: none;"><code font-size="18" style="white-space: pre;"><span>User-agent: * 
</span>Disallow: /private/
<span>Crawl-delay: </span><span class="token" style="color: rgb(183, 107, 1);">10</span></code></div></div></pre>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">The <span class="MuiBox-root mui-1vu004u">User-agent</span> line specifies which crawler the rules apply to. In this case, <span class="MuiBox-root mui-1vu004u">*</span> means all crawlers. The <span class="MuiBox-root mui-1vu004u">Disallow</span> line specifies which pages the crawler is not allowed to crawl. In this case, the crawler is not allowed to crawl any pages in the <span class="MuiBox-root mui-1vu004u">/private/</span> directory. The <span class="MuiBox-root mui-1vu004u">Crawl-delay</span> line specifies how many seconds the crawler should wait between requests. In this case, 10 seconds.</div>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">To ensure politeness and adhere to <span class="MuiBox-root mui-1vu004u">robots.txt</span>, we will need to do two things:</div>
<ol style="list-style: outside decimal;">
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0"><strong>Respect <span class="MuiBox-root mui-1vu004u">robots.txt</span></strong>: Before crawling a page, we will need to check the <span class="MuiBox-root mui-1vu004u">robots.txt</span> file to see if we are allowed to crawl the page. If we are not allowed to crawl the page, we will need to skip it. We will also need to respect the <span class="MuiBox-root mui-1vu004u">Crawl-delay</span> directive and wait the specified number of seconds between requests.</div></li>
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0"><strong>Rate limiting</strong>: We will want to limit the number of requests we make to any single domain. The industry standard is to limit the number of requests to 1 request per second.</div></li>
</ol>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">Let's start with the first point: respecting <span class="MuiBox-root mui-1vu004u">robots.txt</span>.</div>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">First, we need to save the <span class="MuiBox-root mui-1vu004u">robots.txt</span> file for each domain we crawl. In the interview, you may have a discussion about how regularly you should check for updates to this file. For simplicity, we'll just assume it's a one-time download.</div>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">With the <span class="MuiBox-root mui-1vu004u">robots.txt</span> file saved, we can check it before crawling a page. We need to consider two things:</div>
<ol style="list-style: outside decimal;">
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0"><strong>Is the crawler allowed to crawl the page?</strong> Easy, just check the <span class="MuiBox-root mui-1vu004u">Disallow</span> directive and confirm that this page is not disallowed. If it is, we can ack the message (remove it from the queue) and move on to the next URL.</div></li>
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0"><strong>How long should we wait between requests?</strong> This is a bit more complex. We need to check the <span class="MuiBox-root mui-1vu004u">Crawl-delay</span> directive and wait the specified number of seconds between requests.</div></li>
</ol>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">To handle the crawl delay, we need to introduce some additional state. We can add a Domain table to our Metadata DB that stores the last time we crawled each domain. This way, we can check the <span class="MuiBox-root mui-1vu004u">Crawl-delay</span> directive and wait the specified number of seconds before crawling the next page. If we pull a url off the queue for a domain that we have already crawled within the <span class="MuiBox-root mui-1vu004u">Crawl-delay</span> time, we'll just put it back on the queue with the appropriate delay so that we can come back to it later.</div>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">To make this clear, the steps would be:</div>
<ol style="list-style: outside decimal;">
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0">Fetch the <span class="MuiBox-root mui-1vu004u">robots.txt</span> file for the domain.</div></li>
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0">Parse the <span class="MuiBox-root mui-1vu004u">robots.txt</span> file and store it in the Metadata DB.</div></li>
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0">When we pull a URL off the queue, check the rules stored in the Metadata DB for that domain.</div></li>
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0">If the URL is disallowed, ack the message and move on to the next URL.</div></li>
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0">If the URL is allowed, check the <span class="MuiBox-root mui-1vu004u">Crawl-delay</span> directive.</div></li>
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0">If the <span class="MuiBox-root mui-1vu004u">Crawl-delay</span> time has not passed since the last crawl, put the URL back on the queue with the appropriate delay.</div></li>
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0">If the <span class="MuiBox-root mui-1vu004u">Crawl-delay</span> time has passed, crawl the page and update the last crawl time for the domain.</div></li>
</ol>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag"><strong>What about rate limiting?</strong></div>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">We also need to respect the rate limit of 1 domain a second. With multiple crawlers, this can get a little trickier since, in theory, all N crawlers could be hitting a single domain at the same time.</div>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">We can implement a global, domain-specific rate limiting mechanism using a centralized data store (like Redis) to track request counts per domain per second. Each crawler, before making a request, checks this store to ensure the rate limit has not been exceeded. We'll use a sliding window algorithm to track the number of requests per domain per second. If the rate limit has been exceeded, the crawler will wait until the next second to make the request.</div>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">A potential issue with this method is the risk of synchronized behavior among multiple crawlers. If several crawlers are waiting to make requests and simultaneously retry when the rate limit window resets, they'll all try and only one will succeed and the process will repeat.</div>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">Fortunately, there is a relatively simple solution to this problem: jitter. By introducing a small amount of randomness to the rate-limiting algorithm, we can prevent synchronized behavior among crawlers. This jitter can be implemented by adding a random delay to each crawler's request, ensuring that they do not all retry at the same time.</div>
<div class="my-4 flex-col w-full undefined"><div class="MuiBox-root mui-10khgmf" style="cursor: pointer;"><div class="MuiGrid-root MuiGrid-container MuiGrid-direction-xs-column mui-1tdxmx0"><div class="MuiGrid-root MuiGrid-item mui-tolxbf"><div class="relative w-full"><button class="MuiButtonBase-root MuiIconButton-root MuiIconButton-sizeSmall mui-wksd04" tabindex="0" type="button" aria-label="zoom-in"><svg class="MuiSvgIcon-root MuiSvgIcon-fontSizeMedium mui-10dohqv" focusable="false" aria-hidden="true" viewBox="0 0 24 24" data-testid="ZoomInIcon"><path d="M15.5 14h-.79l-.28-.27C15.41 12.59 16 11.11 16 9.5 16 5.91 13.09 3 9.5 3S3 5.91 3 9.5 5.91 16 9.5 16c1.61 0 3.09-.59 4.23-1.57l.27.28v.79l5 4.99L20.49 19zm-6 0C7.01 14 5 11.99 5 9.5S7.01 5 9.5 5 14 7.01 14 9.5 11.99 14 9.5 14"></path><path d="M12 10h-2v2H9v-2H7V9h2V7h1v2h2z"></path></svg><span class="MuiTouchRipple-root mui-w0pj6f"></span></button><div class="w-full"><img class="w-full max-w-full max-h-full" src="https://d248djf5mc6iku.cloudfront.net/excalidraw/4b3476d3920b1cec33ea1f3f2e7a7303" alt="Robots.txt and Rate Limiting"></div></div></div><div class="MuiGrid-root MuiGrid-item mui-1wxaqej"><span class="MuiTypography-root MuiTypography-caption mui-17cupi8">Robots.txt and Rate Limiting</span></div></div></div></div>
<h3 class="MuiTypography-root MuiTypography-h4 mui-hkpafq" id="3-how-to-scale-to-10b-pages-and-efficiently-crawl-them-in-under-5-days">3) How to scale to 10B pages and efficiently crawl them in under 5 days?</h3>
<div class="my-6"><div class="MuiBox-root mui-1147lff"><div class="MuiBox-root mui-zvu67g"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="w-6 h-6 heroicon-sw-2"><path stroke-linecap="round" stroke-linejoin="round" d="M12 18v-5.25m0 0a6.01 6.01 0 0 0 1.5-.189m-1.5.189a6.01 6.01 0 0 1-1.5-.189m3.75 7.478a12.06 12.06 0 0 1-4.5 0m3.75 2.383a14.406 14.406 0 0 1-3 0M14.25 18v-.192c0-.983.658-1.823 1.508-2.316a7.5 7.5 0 1 0-7.517 0c.85.493 1.509 1.333 1.509 2.316V18"></path></svg></div><div class="MuiBox-root mui-79elbk"><div style="overflow: hidden; max-height: 300px;"><div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">I generally suggest you save any scaling discussion until the end of the interview. This is because you'll have a clearer picture of the full system and can make more informed decisions about where to scale. For example, can scaling been our first deep dive we would have been missing out on bottlenecks like the parser workers introduced in subsequent deep dives.</div></div></div></div></div>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">Since scalability and efficiency go hand in hand, we'll tackle these two requirements together.</div>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">First, let's talk about how we can scale the crawler to handle 10B pages in under 5 days. Our one lonely machine won't be able to do this alone, so we need to parallelize the crawling process. But, how many crawler machines will we need?</div>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">To reason about this, we should recognize that this is an I/O intensive task. If we take our average page size of 2MB which we gathered during our non-functional requirements, we can estimate where our bandwidth will be capped.</div>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">In the AWS ecosystem, a network optimized instance can handle about 400 Gbps. This means that a single instance, from a network perspective, can handle about <span class="MuiBox-root mui-1vu004u">400 Gbps / 8 bits/byte / 2MB/page = 25,000 pages/second</span>. That's a ton, but it's likely not actually possible.</div>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">Now there is no way we can make use of all this bandwidth maximally. There will be practical limitations on the number of requests we can make per second dictated by factors like server response latency, DNS resolution, rate limiting, politeness, retries, etc.</div>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">We get very hand-wavy here, but let's say that we can utilize 30% of the available bandwidth. This would give us <span class="MuiBox-root mui-1vu004u">25,000 pages/second * 30% = 7,500 pages/second</span>.</div>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">To estimate the total number of high powered machines we need, we can divide the total number of pages by the number of pages we can crawl per second. This gives us <span class="MuiBox-root mui-1vu004u">10,000,000,000 pages / 7,500 pages/second = 1,333,333 seconds = 15.4 days for a single machine</span>. This scales linearly, so we can divide this by the number of machines we have to get the total time to crawl all the pages: <span class="MuiBox-root mui-1vu004u">15.4 days / 4 machines = 3.85 days</span>. This is under our 5-day requirement, so we're good to go.</div>
<div class="my-6"><div class="MuiBox-root mui-o9fqh4"><div class="MuiBox-root mui-3t6lyr"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="w-6 h-6 heroicon-sw-2"><path stroke-linecap="round" stroke-linejoin="round" d="M12 9v3.75m-9.303 3.376c-.866 1.5.217 3.374 1.948 3.374h14.71c1.73 0 2.813-1.874 1.948-3.374L13.949 3.378c-.866-1.5-3.032-1.5-3.898 0L2.697 16.126ZM12 15.75h.007v.008H12v-.008Z"></path></svg></div><div class="MuiBox-root mui-79elbk"><div style="overflow: hidden; max-height: 300px;"><div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">There are a lot of assumptions in these estimations and, in reality, you would need to do load testing to get a more accurate number. But for an interview, it's less about being right and more about showing that you can reason through the problem.</div></div></div></div></div>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag"><strong>What about the parser workers?</strong></div>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">This should be easier, as the task is relatively straightforward. They just need to download the HTML from blob storage, extract the text data, and store it back in blob storage. We need to make sure this keeps pace with our crawlers. Rather than estimating how many we need, we can just scale this up and down dynamically based on the number of pages in the <span class="MuiBox-root mui-1vu004u">Further Processing Queue</span>. This could be via Lambda functions, ECS tasks, or any other serverless technology.</div>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag"><strong>Don't forget about DNS!</strong></div>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">DNS is one potential bottleneck that is often overlooked. If we're using a 3rd party DNS provider, we'll want to make sure they can handle the load. Most 3rd party providers have rate limits that can be increased by throwing money at them. While this is certainly an option, especially given our time constraints, it's worth considering other optimizations:</div>
<ol style="list-style: outside decimal;">
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0"><strong>DNS caching</strong>: We can cache DNS lookups in our crawlers to reduce the number of DNS requests we need to make. This way all URLs to the same domain will reuse the same DNS lookup.</div></li>
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0"><strong>Multiple DNS providers</strong>: We can use multiple DNS providers and round-robin between them. This can help distribute the load across multiple providers and reduce the risk of hitting rate limits.</div></li>
</ol>
<div class="my-6"><div class="MuiBox-root mui-1ygn9bx"><div class="MuiBox-root mui-14185gn"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="w-6 h-6 heroicon-sw-2"><path stroke-linecap="round" stroke-linejoin="round" d="M12 9v3.75m9-.75a9 9 0 1 1-18 0 9 9 0 0 1 18 0Zm-9 3.75h.008v.008H12v-.008Z"></path></svg></div><div class="MuiBox-root mui-79elbk"><div style="overflow: hidden; max-height: 300px;"><div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">The multiple DNS providers approach was suggested by a Staff candidate in an interview I conducted fairly recently. I really liked this idea. It's simple, but I love how practical it is. It breaks out of the "academic answer" and shows that the candidate is thinking about real-world constraints and solutions.</div></div></div></div></div>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag"><strong>Now let's focus more on efficiency.</strong></div>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">To be as efficient as possible, we will want to ensure we don't waste our time crawling pages that have already been crawled.</div>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">We can first check if a URL has already been crawled by checking the Metadata DB before putting it on the queue. If it has, we can skip it. This is a simple optimization that can save us a lot of time.</div>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">But what about when different URLs point to the same page? This is a common occurrence on the web. For example, <span class="MuiBox-root mui-1vu004u">http://example.com</span> and <span class="MuiBox-root mui-1vu004u">http://www.example.com</span> might point to the same page. It's also common for totally different domains to have exactly the same content (a maybe depressing fact about the internet). For these cases, we can't just compare the URLs, instead, we'll want to compare a hash of the content. Let discuss a couple options:</div>
<div class="my-6 flex flex-col gap-4"><div class="MuiPaper-root MuiPaper-elevation MuiPaper-rounded MuiPaper-elevation0 MuiAccordion-root MuiAccordion-rounded MuiAccordion-gutters mui-11r69q9"><div class="MuiButtonBase-root MuiAccordionSummary-root MuiAccordionSummary-gutters mui-3ujfba" tabindex="0" role="button" aria-expanded="false" aria-controls="panel1bh-content" id="panel1bh-header"><div class="MuiAccordionSummary-content MuiAccordionSummary-contentGutters mui-l0jafl"><p class="MuiTypography-root MuiTypography-body1 mui-h8owmt">Great Solution: Hash and Store in Metadata DB w/ Index</p></div><div class="MuiAccordionSummary-expandIconWrapper mui-awtdfi"><svg class="MuiSvgIcon-root MuiSvgIcon-fontSizeMedium mui-10dohqv" focusable="false" aria-hidden="true" viewBox="0 0 24 24" data-testid="ExpandMoreIcon"><path d="M16.59 8.59 12 13.17 7.41 8.59 6 10l6 6 6-6z"></path></svg></div></div><div class="MuiCollapse-root MuiCollapse-vertical MuiCollapse-hidden mui-a0y2e3" style="min-height: 0px;"><div class="MuiCollapse-wrapper MuiCollapse-vertical mui-hboir5"><div class="MuiCollapse-wrapperInner MuiCollapse-vertical mui-8atqhb"><div aria-labelledby="panel1bh-header" id="panel1bh-content" role="region" class="MuiAccordion-region"><div class="MuiAccordionDetails-root mui-u7qq7e"><h6 class="MuiTypography-root MuiTypography-body1 mui-1quhbks" id="approach-3">Approach</h6><div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">We could hash the content of the page and store this hash in our URL table in the Metadata DB. When we fetch a new URL, we hash the content and compare it to the hashes in the Metadata DB. If we find a match, we skip the page. To make sure the look up is fast, we need to build an index on the hash column in the Metadata DB. This would allow us to quickly look up the hash of the new URL and see if it already exists in the DB.</div><h6 class="MuiTypography-root MuiTypography-body1 mui-1quhbks" id="challenges-3">Challenges</h6><div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">While the index wil become large and may slow down writes, this would be overly pessimistic. Modern databases are quite efficient at handling indexes, even large ones. While it's true that maintaining an index incurs overhead, this overhead is generally well-optimized in modern systems so it's safe to overlook this concern.</div></div></div></div></div></div></div><div class="MuiPaper-root MuiPaper-elevation MuiPaper-rounded MuiPaper-elevation0 MuiAccordion-root MuiAccordion-rounded MuiAccordion-gutters mui-11r69q9"><div class="MuiButtonBase-root MuiAccordionSummary-root MuiAccordionSummary-gutters mui-3ujfba" tabindex="0" role="button" aria-expanded="false" aria-controls="panel1bh-content" id="panel1bh-header"><div class="MuiAccordionSummary-content MuiAccordionSummary-contentGutters mui-l0jafl"><p class="MuiTypography-root MuiTypography-body1 mui-h8owmt">Great Solution: Bloom Filter</p></div><div class="MuiAccordionSummary-expandIconWrapper mui-awtdfi"><svg class="MuiSvgIcon-root MuiSvgIcon-fontSizeMedium mui-10dohqv" focusable="false" aria-hidden="true" viewBox="0 0 24 24" data-testid="ExpandMoreIcon"><path d="M16.59 8.59 12 13.17 7.41 8.59 6 10l6 6 6-6z"></path></svg></div></div><div class="MuiCollapse-root MuiCollapse-vertical MuiCollapse-hidden mui-a0y2e3" style="min-height: 0px;"><div class="MuiCollapse-wrapper MuiCollapse-vertical mui-hboir5"><div class="MuiCollapse-wrapperInner MuiCollapse-vertical mui-8atqhb"><div aria-labelledby="panel1bh-header" id="panel1bh-content" role="region" class="MuiAccordion-region"><div class="MuiAccordionDetails-root mui-u7qq7e"><h6 class="MuiTypography-root MuiTypography-body1 mui-1quhbks" id="approach-4">Approach</h6><div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">Another possible approach is to use a Bloom filter. A Bloom filter is a probabilistic data structure that allows us to test whether an element is a member of a set. It can tell us definitively if an element is not in the set, but it can only tell us with some probability if an element is in the set. This is perfect for our use case. We can use a Bloom filter to store the hashes of the content of the pages we have already crawled. When we fetch a new URL, we hash the content and check the Bloom filter. If the hash is not in the Bloom filter, we know we haven't crawled this page before. If the hash is in the Bloom filter, we know we have crawled this page before and can skip it.</div><div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">From a technology perspective, we can use Redis to store the Bloom filter. Redis has a built-in data structure called a <span class="MuiBox-root mui-1vu004u">Bloom filter</span> that we can use for this purpose.</div><h6 class="MuiTypography-root MuiTypography-body1 mui-1quhbks" id="challenges-4">Challenges</h6><div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">The main challenge with a Bloom filter is that it can give false positives. This means that it might tell us that we have crawled a page when we actually haven't. We could argue that this is an acceptable trade-off for the performance benefits and can configure our bloom filter to reduce the probability of false positives by increasing the size of the filter and the number of hash functions used.</div></div></div></div></div></div></div></div>
<div class="my-6"><div class="MuiBox-root mui-1ygn9bx"><div class="MuiBox-root mui-14185gn"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="w-6 h-6 heroicon-sw-2"><path stroke-linecap="round" stroke-linejoin="round" d="M12 9v3.75m9-.75a9 9 0 1 1-18 0 9 9 0 0 1 18 0Zm-9 3.75h.008v.008H12v-.008Z"></path></svg></div><div class="MuiBox-root mui-79elbk"><div style="overflow: hidden; max-height: 300px;"><div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">To be honest, I think the bloom filter here is a bit overkill. It's a cool data structure, and it's fun to talk about in an interview, but I think the index approach is more practical. It's simpler, and modern DB indexes are quite efficient. I note this as a solution more because candidates always bring it up. I assume this is because it's a common solution in the literature.</div></div></div></div></div>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag"><strong>Last thing! Watch out for crawler traps</strong></div>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">Crawler traps are pages that are designed to keep crawlers on the site indefinitely. They can be created by having a page that links to itself many times or by having a page that links to many other pages on the site. If we're not careful, we could end up crawling the same site over and over again and never finish.</div>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">Fortunately the solution is pretty straight forward, we can implement a maximum depth for our crawlers. We can add a <span class="MuiBox-root mui-1vu004u">depth</span> field to our URL table in the Metadata DB and increment this field each time we follow a link. If the depth exceeds a certain threshold, we can stop crawling the page. This will prevent us from getting stuck in a crawler trap.</div>
<div class="my-4 flex-col w-full undefined"><div class="MuiBox-root mui-10khgmf" style="cursor: pointer;"><div class="MuiGrid-root MuiGrid-container MuiGrid-direction-xs-column mui-1tdxmx0"><div class="MuiGrid-root MuiGrid-item mui-tolxbf"><div class="relative w-full"><button class="MuiButtonBase-root MuiIconButton-root MuiIconButton-sizeSmall mui-wksd04" tabindex="0" type="button" aria-label="zoom-in"><svg class="MuiSvgIcon-root MuiSvgIcon-fontSizeMedium mui-10dohqv" focusable="false" aria-hidden="true" viewBox="0 0 24 24" data-testid="ZoomInIcon"><path d="M15.5 14h-.79l-.28-.27C15.41 12.59 16 11.11 16 9.5 16 5.91 13.09 3 9.5 3S3 5.91 3 9.5 5.91 16 9.5 16c1.61 0 3.09-.59 4.23-1.57l.27.28v.79l5 4.99L20.49 19zm-6 0C7.01 14 5 11.99 5 9.5S7.01 5 9.5 5 14 7.01 14 9.5 11.99 14 9.5 14"></path><path d="M12 10h-2v2H9v-2H7V9h2V7h1v2h2z"></path></svg><span class="MuiTouchRipple-root mui-w0pj6f"></span></button><div class="w-full"><img class="w-full max-w-full max-h-full" src="https://d248djf5mc6iku.cloudfront.net/excalidraw/367e7851cf16a6bfce6db521a4f9e7ce" alt="Scale and Efficiency"></div></div></div><div class="MuiGrid-root MuiGrid-item mui-1wxaqej"><span class="MuiTypography-root MuiTypography-caption mui-17cupi8">Scale and Efficiency</span></div></div></div></div>
<h3 class="MuiTypography-root MuiTypography-h4 mui-hkpafq" id="some-additional-deep-dives-you-might-consider">Some additional deep dives you might consider</h3>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">Of course, I can't cover everything in this guide. Here are a few additional deep dives you might consider on your own:</div>
<ol style="list-style: outside decimal;">
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0"><strong>How to handle dynamic content</strong>: Many websites are built with JavaScript frameworks like React or Angular. This means that the content of the page is not in the HTML that is returned by the server, but is instead loaded dynamically by the JavaScript. To handle this, we'll need to use a headless browser like Puppeteer to render the page and extract the content.</div></li>
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0"><strong>How to monitor the health of the system</strong>: We'll want to monitor the health of the system to ensure that everything is running smoothly. We can use a monitoring service like Datadog or New Relic to monitor the performance of the crawlers and parser workers and to alert us if anything goes wrong.</div></li>
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0"><strong>How to handle large files</strong>: Some websites have very large files that we may not want to download. We can use the <span class="MuiBox-root mui-1vu004u">Content-Length</span> header to determine the size of the file before downloading it and skip files that are too large.</div></li>
<li class="MuiListItem-root MuiListItem-gutters MuiListItem-padding mui-ioa8ei"><div class="MuiBox-root mui-0"><strong>How to handle continual updates</strong>: While our requirements are for a one-time crawl, we may want to consider how we would handle continual updates to the data. This could be that we plan to re-train the model every month or that our crawler is for a search engine that needs to be updated regularly. I'd suggest adding a new component "URL Scheduler" that is responsible for scheduling URLs to be crawled. So rather than putting URLs on the queue directly from the parser workers, the parser workers would put URLs in the Metadata DB and the URL Scheduler would be responsible for scheduling URLs to be crawled by using some logic base on last crawl time, popularity, etc.</div></li>
</ol>
<h2 class="MuiTypography-root MuiTypography-h3 mui-1rzqq5q" id="what-is-expected-at-each-level"><a class="MuiTypography-root MuiTypography-inherit MuiLink-root MuiLink-underlineHover mui-pvpazu" href="https://www.hellointerview.com/blog/the-system-design-interview-what-is-expected-at-each-level" target="_blank" rel="noopener noreferrer" style="color: rgb(99, 115, 129); cursor: pointer; font-weight: 600; text-decoration: underline;">What is Expected at Each Level?</a></h2>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">Ok, that was a lot. You may be thinking, ‚Äúhow much of that is actually required from me in an interview?‚Äù Let‚Äôs break it down.</div>
<h3 class="MuiTypography-root MuiTypography-h4 mui-hkpafq" id="mid-level">Mid-level</h3>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag"><strong>Breadth vs. Depth:</strong> A mid-level candidate will be mostly focused on breadth (80% vs 20%). You should be able to craft a high-level design that meets the functional requirements you've defined, but many of the components will be abstractions with which you only have surface-level familiarity.</div>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag"><strong>Probing the Basics:</strong> Your interviewer will spend some time probing the basics to confirm that you know what each component in your system does. For example, if you add an Queue, expect that they may ask you what it does and how it works (at a high level). In short, the interviewer is not taking anything for granted with respect to your knowledge.</div>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag"><strong>Mixture of Driving and Taking the Backseat:</strong> You should drive the early stages of the interview in particular, but the interviewer doesn‚Äôt expect that you are able to proactively recognize problems in your design with high precision. Because of this, it‚Äôs reasonable that they will take over and drive the later stages of the interview while probing your design.</div>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag"><strong>The Bar for Web Crawler:</strong> For this question, an E4 candidate will be able to understand the high-level data flow and implent a simple system (like our high-level design) which can effectively crawl the web. They should be able to discuss the basics of how to handle politeness and adhere to <span class="MuiBox-root mui-1vu004u">robots.txt</span>. They should have some idea of how to scale the system, but and depth on queueing technologies and rate limiting is not necessarily expected.</div>
<h3 class="MuiTypography-root MuiTypography-h4 mui-hkpafq" id="senior">Senior</h3>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag"><strong>Depth of Expertise</strong>: As a senior candidate, expectations shift towards more in-depth knowledge ‚Äî about 60% breadth and 40% depth. This means you should be able to go into technical details in areas where you have hands-on experience. It's crucial that you demonstrate a deep understanding of key concepts and technologies relevant to the task at hand.</div>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag"><strong>Advanced System Design</strong>: You should be familiar with advanced system design principles. For example, knowing how how queues or caching works is essential. The interviewer knows you know the small stuff (REST API, data normalization, etc) so you can breeze through that at a high level so you have time to get into what is interesting. Your ability to navigate these advanced topics with confidence and clarity is key.</div>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag"><strong>Articulating Architectural Decisions</strong>: You should be able to clearly articulate the pros and cons of different architectural choices, especially how they impact scalability, performance, and maintainability. You justify your decisions and explain the trade-offs involved in your design choices.</div>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag"><strong>Problem-Solving and Proactivity</strong>: You should demonstrate strong problem-solving skills and a proactive approach. This includes anticipating potential challenges in your designs and suggesting improvements. You need to be adept at identifying and addressing bottlenecks, optimizing performance, and ensuring system reliability.</div>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag"><strong>The Bar for Web Crawler</strong>: For a senior candidate, the bar is higher. They should be able to discuss the high-level design and then dive into the details of how to handle politeness and adhere to <span class="MuiBox-root mui-1vu004u">robots.txt</span>. They should be able to discuss how to scale the system and how to efficiently crawl pages within the 10 day time frame.</div>
<h3 class="MuiTypography-root MuiTypography-h4 mui-hkpafq" id="staff">Staff+</h3>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag"><strong>Emphasis on Depth</strong>: As a staff+ candidate, the expectation is a deep dive into the nuances of system design ‚Äî I'm looking for about 40% breadth and 60% depth in your understanding. This level is all about demonstrating that, while you may not have solved this particular problem before, you have solved enough problems in the real world to be able to confidently design a solution backed by your experience.</div>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag">You should know which technologies to use, not just in theory but in practice, and be able to draw from your past experiences to explain how they‚Äôd be applied to solve specific problems effectively. The interviewer knows you know the small stuff (REST API, data normalization, etc) so you can breeze through that at a high level so you have time to get into what is interesting.</div>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag"><strong>High Degree of Proactivity</strong>: At this level, an exceptional degree of proactivity is expected. You should be able to identify and solve issues independently, demonstrating a strong ability to recognize and address the core challenges in system design. This involves not just responding to problems as they arise but anticipating them and implementing preemptive solutions. Your interviewer should intervene only to focus, not to steer.</div>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag"><strong>Practical Application of Technology</strong>: You should be well-versed in the practical application of various technologies. Your experience should guide the conversation, showing a clear understanding of how different tools and systems can be configured in real-world scenarios to meet specific requirements.</div>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag"><strong>Complex Problem-Solving and Decision-Making</strong>: Your problem-solving skills should be top-notch. This means not only being able to tackle complex technical challenges but also making informed decisions that consider various factors such as scalability, performance, reliability, and maintenance.</div>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag"><strong>Advanced System Design and Scalability</strong>: Your approach to system design should be advanced, focusing on scalability and reliability, especially under high load conditions. This includes a thorough understanding of distributed systems, load balancing, caching strategies, and other advanced concepts necessary for building robust, scalable systems.</div>
<div class="MuiTypography-root MuiTypography-body1 mui-1p1f0ag"><strong>The Bar for Web Crawler:</strong> For a staff+ candidate, expectations are high regarding depth and quality of solutions, particularly for the complex scenarios discussed earlier. Great candidates are diving deep into at least 3+ key areas, showcasing not just proficiency but also innovative thinking and optimal solution-finding abilities. A crucial indicator of a staff+ candidate's caliber is the level of insight and knowledge they bring to the table. A good measure for this is if the interviewer comes away from the discussion having gained new understanding or perspectives. If you did all the deep dives above (even if not to the same level of completeness), you're in a good spot.</div>
</body>
</html>